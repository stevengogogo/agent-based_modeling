{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Sensitivity analysis for a NetLogo model with SALib and ipyparallel\n",
    "\n",
    "This provides a more advanced example of interaction between NetLogo and a Python environment, using the SALib library (Herman & Usher, 2017; available through the pip package manager) to sample and analyze a suitable experimental design for a Sobol global sensitivity analysis. Furthermore, the ipyparallel package (also available on pip) is used to parallelize the simulations.\n",
    "\n",
    "All files used in the example are available from the pyNetLogo repository at https://github.com/quaquel/pyNetLogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ensuring compliance of code with both python2 and python3\n",
    "\n",
    "from __future__ import division, print_function\n",
    "try:\n",
    "    from itertools import izip as zip\n",
    "except ImportError: # will be 3.x series\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "import pyNetLogo\n",
    "\n",
    "#Import the sampling and analysis modules for a Sobol variance-based \n",
    "#sensitivity analysis\n",
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SALib relies on a problem definition dictionary which contains the number of input parameters to sample, their names (which should here correspond to a NetLogo global variable), and the sampling bounds. Documentation for SALib can be found at https://salib.readthedocs.io/en/latest/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem = { \n",
    "  'num_vars': 6,\n",
    "  'names': ['random-seed',\n",
    "            'grass-regrowth-time',\n",
    "            'sheep-gain-from-food',\n",
    "            'wolf-gain-from-food',\n",
    "            'sheep-reproduce',\n",
    "            'wolf-reproduce'], \n",
    "  'bounds': [[1, 100000],\n",
    "             [20., 40.], \n",
    "             [2., 8.], \n",
    "             [16., 32.],\n",
    "             [2., 8.],\n",
    "             [2., 8.]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SALib sampler will automatically generate an appropriate number of samples for Sobol analysis, using a revised Saltelli sampling sequence. To calculate first-order, second-order and total sensitivity indices, this gives a sample size of _n(2p+2)_, where _p_ is the number of input parameters, and _n_ is a baseline sample size which should be large enough to stabilize the estimation of the indices. For this example, we use _n_ = 1000, for a total of 14000 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "param_values = saltelli.sample(problem, n, calc_second_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler generates an input array of shape (_n(2p+2)_, _p_) with rows for each experiment and columns for each input parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the experiments in parallel using ipyparallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ipyparallel is a standalone package (available through the pip package manager) which can be used to interactively run parallel tasks from IPython on a single PC, but also on multiple computers. On machines with multiple cores, this can significantly improve performance: for instance, the multiple simulations required for a sensitivity analysis are easy to run in parallel. Documentation for Ipyparallel is available at http://ipyparallel.readthedocs.io/en/latest/intro.html.\n",
    "\n",
    "Ipyparallel first requires starting a controller and multiple engines, which can be done from a terminal or command prompt with the following:\n",
    "\n",
    "`ipcluster start -n 4` \n",
    "\n",
    "The optional -n argument specifies the number of processes to start (4 in this case).\n",
    "\n",
    "Next, we can connect the interactive notebook to the started cluster by instantiating a client, and checking that client.ids returns a list of 4 available engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel\n",
    "\n",
    "client = ipyparallel.Client()\n",
    "client.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up the engines so that they can run the simulations, using a \"direct view\" that accesses all engines.\n",
    "\n",
    "We first need to change the working directories to import pyNetLogo on the engines (assuming the pyNetLogo module is located in the same directory as this notebook, rather than being on the Python path). This also ensures we have the proper path to the file we need to load. We also send the SALib problem definition variable to the workspace of the engines, so that it can be used in the simulation.\n",
    "\n",
    "Note: there are various solutions to both problems. For example, we could make the NetLogo file a keyword argument and pass the absolute path to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direct_view = client[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Push the current working directory of the notebook to a \"cwd\" variable on the engines that can be accessed later\n",
    "direct_view.push(dict(cwd=os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Push the \"problem\" variable from the notebook to a corresponding variable on the engines\n",
    "direct_view.push(dict(problem=problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%%px` command can be added to a notebook cell to run it in parallel on each of the engines. Here the code first involves some imports and a change of the working directory. We then start a link to NetLogo, and load the example model on each of the engines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "\n",
    "import os\n",
    "os.chdir(cwd)\n",
    "\n",
    "import pyNetLogo\n",
    "import pandas as pd\n",
    "\n",
    "netlogo = pyNetLogo.NetLogoLink(gui=False)\n",
    "netlogo.load_model(r'Wolf Sheep Predation_v6.nlogo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the IPyparallel map functionality to run the sampled experiments, now using a \"load balanced\" view to automatically handle the scheduling and distribution of the simulations across the engines. This is for instance useful when simulations may take different amounts of time.\n",
    "\n",
    "We first set up a simulation function that takes a single experiment (i.e. a vector of input parameters) as an argument, and returns the outcomes of interest in a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulation(experiment):\n",
    "    \n",
    "    #Set the input parameters\n",
    "    for i, name in enumerate(problem['names']):\n",
    "        if name == 'random-seed':\n",
    "            #The NetLogo random seed requires a different syntax\n",
    "            netlogo.command('random-seed {}'.format(experiment[i]))\n",
    "        else:\n",
    "            #Otherwise, assume the input parameters are global variables\n",
    "            netlogo.command('set {0} {1}'.format(name, experiment[i]))\n",
    "\n",
    "    netlogo.command('setup')\n",
    "    #Run for 100 ticks and return the number of sheep and wolf agents at each time step\n",
    "    counts = netlogo.repeat_report(['count sheep','count wolves'], 100)    \n",
    "    \n",
    "    results = pd.Series([counts['count sheep'].values.mean(), \n",
    "                         counts['count wolves'].values.mean()], \n",
    "                         index=['Avg. sheep', 'Avg. wolves'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a load balanced view and run the simulation with the `map_sync` method. This method takes a function and a Python sequence as arguments, applies the function to each element of the sequence, and returns results once all computations are finished.\n",
    "\n",
    "In this case, we pass the simulation function and the array of experiments (param_values), so that the function will be executed for each row of the array.\n",
    "\n",
    "The DataFrame constructor is then used to immediately build a DataFrame from the results (which are returned as a list of Series). The `to_csv` method provides a simple way of saving the results to disk; pandas supports several more advanced storage options, such as serialization with msgpack, or hierarchical HDF5 storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lview = client.load_balanced_view()\n",
    "\n",
    "results = pd.DataFrame(lview.map_sync(simulation, param_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('Sobol_parallel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SALib for sensitivity analysis\n",
    "\n",
    "We can then proceed with the analysis, first using a histogram to visualize output distributions for each outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,len(results.columns), sharey=True)\n",
    "\n",
    "for i, n in enumerate(results.columns):\n",
    "    ax[i].hist(results[n], 20)\n",
    "    ax[i].set_xlabel(n)\n",
    "ax[0].set_ylabel('Counts')\n",
    "\n",
    "fig.set_size_inches(10,4)\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate scatter plots can be useful to visualize relationships between each input parameter and the outputs. Taking the outcome for the average sheep count as an example, we obtain the following, using the scipy library to calculate the Pearson correlation coefficient (r) for each parameter, and the seaborn library to plot a linear trend fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "nrow=2\n",
    "ncol=3\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, sharey=True)\n",
    "\n",
    "y = results['Avg. sheep']\n",
    "\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    x = param_values[:,i]\n",
    "    sns.regplot(x, y, ax=a, ci=None, color='k',scatter_kws={'alpha':0.2, 's':4, 'color':'gray'})\n",
    "    pearson = scipy.stats.pearsonr(x, y)\n",
    "    a.annotate(\"r: {:6.3f}\".format(pearson[0]), xy=(0.15, 0.85), xycoords='axes fraction',fontsize=13)\n",
    "    if divmod(i,ncol)[1]>0:\n",
    "        a.get_yaxis().set_visible(False)\n",
    "    a.set_xlabel(problem['names'][i])\n",
    "    a.set_ylim([0,1.1*np.max(y)])\n",
    "\n",
    "fig.set_size_inches(9,9,forward=True) \n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates a positive relationship between the \"sheep-gain-from-food\" parameter and the mean sheep count, and negative relationships for the \"wolf-gain-from-food\" and \"wolf-reproduce\" parameters.\n",
    "\n",
    "We can then use SALib to calculate first-order (S1), second-order (S2) and total (ST) Sobol indices, to estimate each input's contribution to output variance as well as input interactions (again using the mean sheep count). By default, 95% confidence intervals are estimated for each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Si = sobol.analyze(problem, results['Avg. sheep'].values, calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple example, we first select and visualize the total and first-order indices for each input, converting the dictionary returned by SALib to a DataFrame. The default pandas plotting method is then used to plot these indices along with their estimated confidence intervals (shown as error bars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Si_filter = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df = pd.DataFrame(Si_filter, index=problem['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Si_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "indices = Si_df[['S1','ST']]\n",
    "err = Si_df[['S1_conf','ST_conf']]\n",
    "\n",
    "indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "fig.set_size_inches(8,4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sheep-gain-from-food\" parameter has the highest ST index, indicating that it contributes over 50% of output variance when accounting for interactions with other parameters. However, it can be noted that confidence bounds are still quite broad with this sample size, particularly for the S1 index (which indicates each input's individual contribution to variance).\n",
    "\n",
    "We can use a more sophisticated visualization to include the second-order interactions between inputs estimated from the S2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "from math import pi\n",
    "\n",
    "\n",
    "def normalize(x, xmin, xmax):\n",
    "    return (x-xmin)/(xmax-xmin)\n",
    "\n",
    "\n",
    "def plot_circles(ax, locs, names, max_s, stats, smax, smin, fc, ec, lw, \n",
    "                 zorder):\n",
    "    s = np.asarray([stats[name] for name in names])\n",
    "    s = 0.01 + max_s * np.sqrt(normalize(s, smin, smax))\n",
    "    \n",
    "    fill = True\n",
    "    for loc, name, si in zip(locs, names, s):\n",
    "        if fc=='w':\n",
    "            fill=False\n",
    "        else:\n",
    "            ec='none'\n",
    "            \n",
    "        x = np.cos(loc)\n",
    "        y = np.sin(loc)\n",
    "        \n",
    "        circle = plt.Circle((x,y), radius=si, ec=ec, fc=fc, transform=ax.transData._b,\n",
    "                            zorder=zorder, lw=lw, fill=True)\n",
    "        ax.add_artist(circle)\n",
    "        \n",
    "\n",
    "def filter(sobol_indices, names, locs, criterion, threshold):\n",
    "    if criterion in ['ST', 'S1', 'S2']:\n",
    "        data = sobol_indices[criterion]\n",
    "        data = np.abs(data)\n",
    "        data = data.flatten() # flatten in case of S2\n",
    "        # TODO:: remove nans\n",
    "        \n",
    "        filtered = ([(name, locs[i]) for i, name in enumerate(names) if \n",
    "                     data[i]>threshold])\n",
    "        filtered_names, filtered_locs = zip(*filtered)\n",
    "    elif criterion in ['ST_conf', 'S1_conf', 'S2_conf']:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise ValueError('unknown value for criterion')\n",
    "\n",
    "    return filtered_names, filtered_locs\n",
    "\n",
    "\n",
    "def plot_sobol_indices(sobol_indices, criterion='ST', threshold=0.01):\n",
    "    '''plot sobol indices on a radial plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sobol_indices : dict\n",
    "                    the return from SAlib\n",
    "    criterion : {'ST', 'S1', 'S2', 'ST_conf', 'S1_conf', 'S2_conf'}, optional\n",
    "    threshold : float\n",
    "                only visualize variables with criterion larger than cutoff\n",
    "             \n",
    "    '''\n",
    "    max_linewidth_s2 = 15#25*1.8\n",
    "    max_s_radius = 0.3\n",
    "    \n",
    "    # prepare data\n",
    "    # use the absolute values of all the indices\n",
    "    #sobol_indices = {key:np.abs(stats) for key, stats in sobol_indices.items()}\n",
    "    \n",
    "    # dataframe with ST and S1\n",
    "    sobol_stats = {key:sobol_indices[key] for key in ['ST', 'S1']}\n",
    "    sobol_stats = pd.DataFrame(sobol_stats, index=problem['names'])\n",
    "\n",
    "    smax = sobol_stats.max().max()\n",
    "    smin = sobol_stats.min().min()\n",
    " \n",
    "    # dataframe with s2\n",
    "    s2 = pd.DataFrame(sobol_indices['S2'], index=problem['names'], \n",
    "                      columns=problem['names'])\n",
    "    s2[s2<0.0]=0. #Set negative values to 0 (artifact from small sample sizes)\n",
    "    s2max = s2.max().max()\n",
    "    s2min = s2.min().min()\n",
    "\n",
    "    names = problem['names']\n",
    "    n = len(names)\n",
    "    ticklocs = np.linspace(0, 2*pi, n+1)\n",
    "    locs = ticklocs[0:-1]\n",
    "\n",
    "    filtered_names, filtered_locs = filter(sobol_indices, names, locs,\n",
    "                                           criterion, threshold)\n",
    "    \n",
    "    # setup figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.grid(False)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_xticks(ticklocs)\n",
    "\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylim(ymax=1.4)\n",
    "    legend(ax)\n",
    "\n",
    "    # plot ST\n",
    "    plot_circles(ax, filtered_locs, filtered_names, max_s_radius, \n",
    "                 sobol_stats['ST'], smax, smin, 'w', 'k', 1, 9)\n",
    "\n",
    "    # plot S1\n",
    "    plot_circles(ax, filtered_locs, filtered_names, max_s_radius, \n",
    "                 sobol_stats['S1'], smax, smin, 'k', 'k', 1, 10)\n",
    "\n",
    "    # plot S2\n",
    "    for name1, name2 in itertools.combinations(zip(filtered_names, filtered_locs), 2):\n",
    "        name1, loc1 = name1\n",
    "        name2, loc2 = name2\n",
    "\n",
    "        weight = s2.ix[name1, name2]\n",
    "        lw = 0.5+max_linewidth_s2*normalize(weight, s2min, s2max)\n",
    "        ax.plot([loc1, loc2], [1,1], c='darkgray', lw=lw, zorder=1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "from matplotlib.legend_handler import HandlerPatch\n",
    "class HandlerCircle(HandlerPatch):\n",
    "    def create_artists(self, legend, orig_handle,\n",
    "                       xdescent, ydescent, width, height, fontsize, trans):\n",
    "        center = 0.5 * width - 0.5 * xdescent, 0.5 * height - 0.5 * ydescent\n",
    "        p = plt.Circle(xy=center, radius=orig_handle.radius)\n",
    "        self.update_prop(p, orig_handle, legend)\n",
    "        p.set_transform(trans)\n",
    "        return [p]\n",
    "\n",
    "def legend(ax):\n",
    "    some_identifiers = [plt.Circle((0,0), radius=5, color='k', fill=False, lw=1),\n",
    "                        plt.Circle((0,0), radius=5, color='k', fill=True),\n",
    "                        plt.Line2D([0,0.5], [0,0.5], lw=8, color='darkgray')]\n",
    "    ax.legend(some_identifiers, ['ST', 'S1', 'S2'],\n",
    "              loc=(1,0.75), borderaxespad=0.1, mode='expand',\n",
    "              handler_map={plt.Circle: HandlerCircle()})\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig = plot_sobol_indices(Si, criterion='ST', threshold=0.005)\n",
    "fig.set_size_inches(7,7)\n",
    "#plt.savefig('JASSS figures/Figure 8 - Interactions.pdf', bbox_inches='tight')\n",
    "#plt.savefig('JASSS figures/Figure 8 - Interactions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the \"sheep-gain-from-food\" variable has strong interactions with the \"wolf-gain-from-food\" and \"wolf-reproduce\" inputs in particular. The size of the ST and S1 circles correspond to the normalized variable importances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
